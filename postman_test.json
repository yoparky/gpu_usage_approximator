{
    "info": {
      "name": "vLLM GPU Memory Calculator API Tests",
      "schema": "https://schema.getpostman.com/json/collection/v2.1.0/collection.json"
    },
    "item": [
      {
        "name": "Estimate GPU Memory - LLaMA-2-7B (Realistic Settings)",
        "request": {
          "method": "POST",
          "header": [
            {
              "key": "Content-Type",
              "value": "application/json"
            }
          ],
          "body": {
            "mode": "raw",
            "raw": "{\n    \"model_name\": \"meta-llama/Llama-2-7b\",\n    \"max_seq_len\": 2048,\n    \"dtype\": \"float16\",\n    \"max_batch_size\": 1,\n    \"gpu_memory_utilization\": 0.9\n}"
          },
          "url": {
            "raw": "http://localhost:8000/estimate-gpu-memory",
            "protocol": "http",
            "host": [
              "localhost"
            ],
            "port": "8000",
            "path": [
              "estimate-gpu-memory"
            ]
          },
          "description": "Estimates GPU memory for LLaMA-2-7B with realistic settings (batch size = 1)"
        },
        "response": [],
        "event": [
          {
            "listen": "test",
            "script": {
              "type": "text/javascript",
              "exec": [
                "// Basic response validation",
                "pm.test(\"Status code is 200\", function () {",
                "    pm.response.to.have.status(200);",
                "});",
                "",
                "pm.test(\"Response is valid JSON\", function () {",
                "    var jsonData = pm.response.json();",
                "    pm.expect(jsonData).to.be.an('object');",
                "});",
                "",
                "// Validate specific memory components",
                "pm.test(\"Memory components are present\", function () {",
                "    var jsonData = pm.response.json();",
                "    pm.expect(jsonData.model_params_memory_gb).to.exist;",
                "    pm.expect(jsonData.activation_memory_gb).to.exist;",
                "    pm.expect(jsonData.min_kv_cache_memory_gb).to.exist;",
                "    pm.expect(jsonData.max_kv_cache_memory_gb).to.exist;",
                "    pm.expect(jsonData.total_max_memory_gb).to.exist;",
                "});",
                "",
                "// Validate expected memory range for LLaMA-2-7B (batch=1)",
                "pm.test(\"Total memory requirement is in expected range\", function () {",
                "    var jsonData = pm.response.json();",
                "    pm.expect(jsonData.total_max_memory_gb).to.be.within(15, 25);",
                "});",
                "",
                "// Log memory breakdown for easy viewing",
                "console.log(\"Memory Breakdown (GB):\");",
                "console.log(JSON.stringify(pm.response.json().components_breakdown, null, 2));"
              ]
            }
          }
        ]
      },
      {
        "name": "Estimate GPU Memory - LLaMA-2-7B (High Throughput)",
        "request": {
          "method": "POST",
          "header": [
            {
              "key": "Content-Type",
              "value": "application/json"
            }
          ],
          "body": {
            "mode": "raw",
            "raw": "{\n    \"model_name\": \"meta-llama/Llama-2-7b\",\n    \"max_seq_len\": 2048,\n    \"dtype\": \"float16\",\n    \"max_batch_size\": 32,\n    \"gpu_memory_utilization\": 0.9\n}"
          },
          "url": {
            "raw": "http://localhost:8000/estimate-gpu-memory",
            "protocol": "http",
            "host": [
              "localhost"
            ],
            "port": "8000",
            "path": [
              "estimate-gpu-memory"
            ]
          },
          "description": "Estimates GPU memory for LLaMA-2-7B with high throughput settings (batch size = 32)"
        },
        "response": [],
        "event": [
          {
            "listen": "test",
            "script": {
              "type": "text/javascript",
              "exec": [
                "pm.test(\"Status code is 200\", function () {",
                "    pm.response.to.have.status(200);",
                "});",
                "",
                "pm.test(\"High batch size significantly increases memory\", function () {",
                "    var jsonData = pm.response.json();",
                "    pm.expect(jsonData.total_max_memory_gb).to.be.above(100);",
                "});",
                "",
                "console.log(\"Memory Breakdown for High Throughput (GB):\");",
                "console.log(JSON.stringify(pm.response.json().components_breakdown, null, 2));"
              ]
            }
          }
        ]
      },
      {
        "name": "Estimate GPU Memory - LLaMA-2-7B (Quantized)",
        "request": {
          "method": "POST",
          "header": [
            {
              "key": "Content-Type",
              "value": "application/json"
            }
          ],
          "body": {
            "mode": "raw",
            "raw": "{\n    \"model_name\": \"meta-llama/Llama-2-7b\",\n    \"max_seq_len\": 2048,\n    \"dtype\": \"float16\",\n    \"max_batch_size\": 1,\n    \"quantization\": \"Q4\",\n    \"gpu_memory_utilization\": 0.9\n}"
          },
          "url": {
            "raw": "http://localhost:8000/estimate-gpu-memory",
            "protocol": "http",
            "host": [
              "localhost"
            ],
            "port": "8000",
            "path": [
              "estimate-gpu-memory"
            ]
          },
          "description": "Estimates GPU memory for LLaMA-2-7B with 4-bit quantization"
        },
        "response": [],
        "event": [
          {
            "listen": "test",
            "script": {
              "type": "text/javascript",
              "exec": [
                "pm.test(\"Status code is 200\", function () {",
                "    pm.response.to.have.status(200);",
                "});",
                "",
                "pm.test(\"Quantization reduces model parameters memory\", function () {",
                "    var jsonData = pm.response.json();",
                "    pm.expect(jsonData.model_params_memory_gb).to.be.below(4);",
                "});",
                "",
                "console.log(\"Memory Breakdown for Quantized Model (GB):\");",
                "console.log(JSON.stringify(pm.response.json().components_breakdown, null, 2));"
              ]
            }
          }
        ]
      },
      {
        "name": "Estimate GPU Memory - With Custom Architecture",
        "request": {
          "method": "POST",
          "header": [
            {
              "key": "Content-Type",
              "value": "application/json"
            }
          ],
          "body": {
            "mode": "raw",
            "raw": "{\n    \"model_name\": \"custom-model\",\n    \"max_seq_len\": 4096,\n    \"dtype\": \"float16\",\n    \"max_batch_size\": 1,\n    \"params_billions\": 13,\n    \"architecture\": {\n        \"num_layers\": 40,\n        \"hidden_size\": 5120,\n        \"num_heads\": 40,\n        \"head_dim\": 128,\n        \"intermediate_size\": 13824\n    },\n    \"gpu_memory_utilization\": 0.9\n}"
          },
          "url": {
            "raw": "http://localhost:8000/estimate-gpu-memory",
            "protocol": "http",
            "host": [
              "localhost"
            ],
            "port": "8000",
            "path": [
              "estimate-gpu-memory"
            ]
          },
          "description": "Estimates GPU memory with custom model architecture details"
        },
        "response": [],
        "event": [
          {
            "listen": "test",
            "script": {
              "type": "text/javascript",
              "exec": [
                "pm.test(\"Status code is 200\", function () {",
                "    pm.response.to.have.status(200);",
                "});",
                "",
                "pm.test(\"Custom architecture is used\", function () {",
                "    var jsonData = pm.response.json();",
                "    pm.expect(jsonData.architecture_used.num_layers).to.equal(40);",
                "    pm.expect(jsonData.architecture_used.hidden_size).to.equal(5120);",
                "});",
                "",
                "console.log(\"Memory Breakdown for Custom Model (GB):\");",
                "console.log(JSON.stringify(pm.response.json().components_breakdown, null, 2));"
              ]
            }
          }
        ]
      },
      {
        "name": "Get Known Architectures",
        "request": {
          "method": "GET",
          "header": [],
          "url": {
            "raw": "http://localhost:8000/known-architectures",
            "protocol": "http",
            "host": [
              "localhost"
            ],
            "port": "8000",
            "path": [
              "known-architectures"
            ]
          },
          "description": "Gets the list of known model architectures"
        },
        "response": [],
        "event": [
          {
            "listen": "test",
            "script": {
              "type": "text/javascript",
              "exec": [
                "pm.test(\"Status code is 200\", function () {",
                "    pm.response.to.have.status(200);",
                "});",
                "",
                "pm.test(\"Response contains model architectures\", function () {",
                "    var jsonData = pm.response.json();",
                "    pm.expect(jsonData.models).to.be.an('object');",
                "    pm.expect(Object.keys(jsonData.models).length).to.be.greaterThan(0);",
                "});"
              ]
            }
          }
        ]
      }
    ]
  }